{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TARS Repo Functional Test Notebook\n",
        "\n",
        "This Colab notebook validates the repository setup, runs tests, and executes both an offline mock analysis and an optional live Gemini analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Clone and install\n",
        "Run this first in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/<your-org-or-user>/tars.git\n",
        "%cd tars\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Run unit tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m unittest discover -s tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Offline functionality test (no Gemini key needed)\n",
        "This monkeypatches `GeminiEvaluator.evaluate_progression` so you can validate sequence-level self-improvement reporting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from tars_analyzer import analyzer\n",
        "from tars_analyzer.models import ConversationProgress, ProgressionEvaluation\n",
        "\n",
        "class FakeEvaluator:\n",
        "    def __init__(self, model='gemini-2.0-flash'):\n",
        "        self.model = model\n",
        "\n",
        "    def evaluate_progression(self, conversations):\n",
        "        ordered = sorted(conversations, key=lambda c: c.timestamp)\n",
        "        items = []\n",
        "        for idx, convo in enumerate(ordered):\n",
        "            items.append(ConversationProgress(\n",
        "                conversation_id=convo.conversation_id,\n",
        "                rank=idx + 1,\n",
        "                overall_agent_quality=6.0 + idx,\n",
        "                improvement_vs_previous=0.0 if idx == 0 else 1.0,\n",
        "                notes='mock sequence improvement'\n",
        "            ))\n",
        "        return ProgressionEvaluation(\n",
        "            overall_summary='Agent improves each step in this mocked run.',\n",
        "            trajectory_label='improving',\n",
        "            trajectory_confidence=9.0,\n",
        "            per_conversation=items\n",
        "        )\n",
        "\n",
        "sample_jsonl = '\\n'.join([\n",
        "    json.dumps({\n",
        "        'conversation_id': 'conv-0',\n",
        "        'timestamp': '2026-01-01T10:00:00Z',\n",
        "        'turns': [\n",
        "            {'role': 'human', 'content': 'Can you plan a trip?'},\n",
        "            {'role': 'agent', 'content': 'Sure, here is a rough plan.'}\n",
        "        ]\n",
        "    }),\n",
        "    json.dumps({\n",
        "        'conversation_id': 'conv-1',\n",
        "        'timestamp': '2026-01-02T10:00:00Z',\n",
        "        'turns': [\n",
        "            {'role': 'human', 'content': 'Can you improve the budget detail?'},\n",
        "            {'role': 'agent', 'content': 'Absolutely, here is a detailed budget with assumptions.'}\n",
        "        ]\n",
        "    }),\n",
        "    json.dumps({\n",
        "        'conversation_id': 'conv-2',\n",
        "        'timestamp': '2026-01-03T10:00:00Z',\n",
        "        'turns': [\n",
        "            {'role': 'human', 'content': 'Add risk mitigation and alternatives.'},\n",
        "            {'role': 'agent', 'content': 'Added fallback options, risks, and trade-offs.'}\n",
        "        ]\n",
        "    })\n",
        "])\n",
        "\n",
        "Path('tmp').mkdir(exist_ok=True)\n",
        "input_path = Path('tmp/mock_conversations.jsonl')\n",
        "output_dir = Path('tmp/mock_output')\n",
        "input_path.write_text(sample_jsonl)\n",
        "\n",
        "original = analyzer.GeminiEvaluator\n",
        "analyzer.GeminiEvaluator = FakeEvaluator\n",
        "try:\n",
        "    report = analyzer.analyze_conversations(input_path, output_dir)\n",
        "finally:\n",
        "    analyzer.GeminiEvaluator = original\n",
        "\n",
        "print('Trajectory:', report['trajectory']['label'])\n",
        "print('First\u2192Last delta:', report['trend_delta_first_to_last'])\n",
        "print('Report files:', list(output_dir.iterdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cat tmp/mock_output/report.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Optional: Live Gemini test\n",
        "Run this only if you have a Gemini API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv('GEMINI_API_KEY'):\n",
        "    os.environ['GEMINI_API_KEY'] = getpass('Enter GEMINI_API_KEY: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m tars_analyzer.cli examples/conversations.jsonl --out output --model gemini-2.0-flash\n",
        "!cat output/report.md"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}