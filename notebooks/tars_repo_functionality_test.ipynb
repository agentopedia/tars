{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TARS Repo Functional Test Notebook\n",
        "\n",
        "This Colab notebook validates the repository setup, runs tests, and executes both an offline mock analysis and an optional live Gemini analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Clone and install\n",
        "Run this first in Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/<your-org-or-user>/tars.git\n",
        "%cd tars\n",
        "!python -m pip install --upgrade pip\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Run unit tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m unittest discover -s tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Offline functionality test (no Gemini key needed)\n",
        "This monkeypatches `GeminiEvaluator` so you can verify report generation end-to-end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "from tars_analyzer import analyzer\n",
        "from tars_analyzer.models import GeminiEvaluation\n",
        "\n",
        "class FakeEvaluator:\n",
        "    def __init__(self, model='gemini-2.0-flash'):\n",
        "        self.model = model\n",
        "\n",
        "    def evaluate(self, conversation):\n",
        "        rank = int(conversation.conversation_id.split('-')[-1])\n",
        "        base = 6.0 + rank\n",
        "        return GeminiEvaluation(\n",
        "            helpfulness=base,\n",
        "            correctness=base,\n",
        "            proactivity=base,\n",
        "            user_satisfaction=base,\n",
        "            confidence=8.5,\n",
        "            notes='mock evaluation'\n",
        "        )\n",
        "\n",
        "sample_jsonl = '\\n'.join([\n",
        "    json.dumps({\n",
        "        'conversation_id': 'conv-0',\n",
        "        'timestamp': '2026-01-01T10:00:00Z',\n",
        "        'turns': [\n",
        "            {'role': 'human', 'content': 'Can you plan a trip?'},\n",
        "            {'role': 'agent', 'content': 'Sure, here is a rough plan.'}\n",
        "        ]\n",
        "    }),\n",
        "    json.dumps({\n",
        "        'conversation_id': 'conv-1',\n",
        "        'timestamp': '2026-01-02T10:00:00Z',\n",
        "        'turns': [\n",
        "            {'role': 'human', 'content': 'Can you improve the budget detail?'},\n",
        "            {'role': 'agent', 'content': 'Absolutely, here is a detailed budget with assumptions.'}\n",
        "        ]\n",
        "    })\n",
        "])\n",
        "\n",
        "Path('tmp').mkdir(exist_ok=True)\n",
        "input_path = Path('tmp/mock_conversations.jsonl')\n",
        "output_dir = Path('tmp/mock_output')\n",
        "input_path.write_text(sample_jsonl)\n",
        "\n",
        "original = analyzer.GeminiEvaluator\n",
        "analyzer.GeminiEvaluator = FakeEvaluator\n",
        "try:\n",
        "    report = analyzer.analyze_conversations(input_path, output_dir)\n",
        "finally:\n",
        "    analyzer.GeminiEvaluator = original\n",
        "\n",
        "print('Trend:', report['trend_label'])\n",
        "print('Average score:', report['average_score'])\n",
        "print('Report files:', list(output_dir.iterdir()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cat tmp/mock_output/report.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Optional: Live Gemini test\n",
        "Run this only if you have a Gemini API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "if not os.getenv('GEMINI_API_KEY'):\n",
        "    os.environ['GEMINI_API_KEY'] = getpass('Enter GEMINI_API_KEY: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tars-analyze examples/conversations.jsonl --out output --model gemini-2.0-flash\n",
        "!cat output/report.md"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}